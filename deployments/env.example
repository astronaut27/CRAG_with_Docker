# OpenAI Configuration (for evaluation)
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-key-here

# Mock API Configuration (for RAG data)
# If running mock API locally, use localhost
# If running mock API in Docker, use mock-api:8000
CRAG_MOCK_API_URL=http://mock-api:8000

# Evaluation Model
# Model used for evaluating predictions
# If using LM Studio/Ollama, set this to your model name (e.g., "llama3", "llama2")
EVALUATION_MODEL_NAME=gpt-4-0125-preview

# Evaluation API Configuration (for LM Studio/Ollama)
# If EVALUATION_API_BASE is set, evaluation will use OpenAI-compatible API instead of default OpenAI API
# For LM Studio: http://localhost:1234/v1
# For Ollama: http://localhost:11434/v1
# Leave empty to use default OpenAI API
EVALUATION_API_BASE=
EVALUATION_API_KEY=

# OpenAI-compatible API Configuration (for Ollama/LM Studio - for answer generation)
# For Ollama: http://localhost:11434/v1
# For LM Studio: http://localhost:1234/v1
OPENAI_API_BASE=http://localhost:11434/v1
OPENAI_MODEL_NAME=llama3
OPENAI_BATCH_SIZE=4
